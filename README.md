# Detecting-Machine-Generated-Text-Comparative-Analysis-of-Deep-Learning-and-Machine-Learning-Models-
This is my Undergraduate Final year project I worked on using Kaggle Dataset with contemporary Deep Learning Models as main focus.
# Abstract 
Large-scale language models (LLMs), such as the GPT-4 from OpenAI 
and the Pathways Language Model from Google, have become indispensable to our
daily lives and work, frequently being used without our conscious 
 knowledge. Subtle flaws in AI-generated writing continue to make it
difficult to distinguish between human-written and AI-generated content,
despite research showing even crowdsourcing workers find it difficult to do
so. These models have garnered a lot of attention because of their possible
downsides, even though they have many advantages that have the potential
to completely transform the way people work and learn.The production of
academic reports or articles with little to no human input is a noteworthy
application of LLMs, demonstrating their potential for work automation.
As a result, scientists have concentrated on creating detectors to deal with
possible wrongdoing related to information provided by LLM. However,
current methods frequently ignore the vital component of generalizability
in favor of accuracy on small datasets. Our study offers a thorough examination
of machine learning (ML) and Deep Learnings techniques that are
intended to differentiate text produced by artificial intelligence (AI) from
language created by humans.Our goal is to solve the problem of accurately
and consistently identifying text generated by artificial intelligence (AI) by
investigating different techniques. We examine a broad spectrum of algorithms,
taking into account their generalizability to various datasets and
circumstances as well as performance measures.By expanding the abstract,
we provide the groundwork for a comprehensive analysis of ML algorithms
for text detection by giving a more extensive description of the importance of
LLMs, the difficulties they present, and the particular focus of our research.

# Findings 

The findings of this paper includes the following:

• Machine learning algorithms naive bayes, Random Forest, SVM , Logistic Regression
as expected traditionally works competitively to produce reliable accuracy and Random
Forest succeeds with 99.16% accuracy.

• However, we have come to the notion that when we are tasked with
detecting machine generated text from student generated text the best
approach is to go through Neural Network. Keeping that in mind
we have compared Simple Neural Networks and Recurrent Neural
Netowrks. The results made it clear that our model is overfitting
and suffers from diminishing gradient effect, to overcome that RNN
especially LSTM model works very well with 99.16% accuracy with
loss function gradually decreasing.

• But at last with knowledge we gained from literature survey Transformers Models
are tailor made for this task, with inclusion of Bidirection encoder Representation 
from Transformers (BERT) 96.53% accuracy.

The short comings of this research are the usage of BERT base model.
With limited hardware resources available we proceeded with BERT base
model over BERT large. That could perform better that BERT Base model
